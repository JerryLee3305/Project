
- 언더샘플링 0.4, stand, 결측치 전부 imputer로 대체

| 모델 | 훈련셋 정확도 | 테스트셋 정확도 | 테스트셋 F1 | Recall | Precision |
| --- | --- | --- | --- | --- | --- |
| 랜덤포레스트 | 0.9553 | 0.9357 | 0.5660 | 0.4457 | 0.7749 |
| XGB | 0.9317 | 0.9311 | 0.5462 | 0.4244 | 0.7658 |
| LGBM | 0.9045 | 0.9039 | 0.4342 | 0.3185 | 0.6817 |
| CatBoost | 0.9508 | 0.9503 | 0.6423 | 0.5260 | 0.8247 |
- 언더샘플링 0.4, robust, 결측치 전부 imputer로 대체

| 모델 | 훈련셋 정확도 | 테스트셋 정확도 | 테스트셋 F1 | Recall | Precision |
| --- | --- | --- | --- | --- | --- |
| 랜덤포레스트 | 0.9555 | 0.9362 | 0.5687 | 0.4483 | 0.7774 |
| XGB | 0.9318 | 0.9310 | 0.5452 | 0.4239 | 0.7640 |
| LGBM | 0.9043 | 0.9037 | 0.4334 | 0.3179 | 0.6807 |
| CatBoost | 0.9511 | 0.9506 | 0.6439 | 0.5280 | 0.8248 |

```python
from autoimpute.imputations import SingleImputer, MultipleImputer, MiceImputer
si = SingleImputer() # pass through data once
mi = MultipleImputer() # pass through data multiple times
mice = MiceImputer()
```

- 언더샘플링 0.4, robust, 결측치 imputer 대체(bank_id 포함하고 돌림)

| 모델 | 훈련셋 정확도 | 테스트셋 정확도 | 테스트셋 F1 | Recall | Precision |
| --- | --- | --- | --- | --- | --- |
| 랜덤포레스트 | 0.9230 | 0.9460 | 0.5073 | 0.3880 | 0.7324 |
| XGB | 0.9287 | 0.9292 | 0.5346 | 0.4131 | 0.7574 |
| LGBM | 0.9016 | 0.9017 | 0.4273 | 0.3118 | 0.6784 |
| CatBoost | 0.9514 | 0.9517 | 0.6486 | 0.5322 | 0.8302 |


| 모델 | 훈련셋 정확도 | 테스트셋 정확도 | 테스트셋 F1 | Recall | Precision |
| --- | --- | --- | --- | --- | --- |
| 랜덤포레스트 | 0.9155 | 0.9998 | 0.4766 | 0.3584 | 0.7112 |
| XGB | 0.9077 | 0.8574 | 0.446 | 0.3303 | 0.6565 |
| LGBM | 0.8912 | 0.8314 | 0.3901 | 0.2799 | 0.6433 |
| CatBoost | 0.9437 | 0.908 | 0.5995 | 0.4875 | 0.7785 |


| 모델 | 훈련셋 정확도 | 테스트셋 정확도 | 테스트셋 F1 | Recall | Precision |
| --- | --- | --- | --- | --- | --- |
| 랜덤포레스트 | 0.9206 |  | 0.4980 | 0.3785 | 0.7277 |
| XGB | 0.90442 | 0.9054 | 0.4347 | 0.3195 | 0.6794 |
| LGBM | 0.8879 | 0.8886 | 0.3789 | 0.2705 | 0.6321 |
| CatBoost | 0.9435 | 0.9442 | 0.5962 | 0.4859 | 0.7711 |

- 범주형 데이터 인코딩을 해싱인코딩으로 진행(결측치 컬럼 없는상태로) + 이후 결측치 imputer 이용해서 예측 + Stand 사용

| 모델 | 훈련셋 정확도 | 테스트셋 정확도 | 테스트셋 F1 | Recall | Precision |
| --- | --- | --- | --- | --- | --- |
| 랜덤포레스트 |  |  |  |  |  |
| XGB |  |  |  |  |  |
| LGBM |  |  |  |  |  |
| CatBoost |  |  |  |  |  |

- 나이를 그룹화 후(카테고리 정수로) 자동 결측치 대체, 오브젝트형 원핫인코딩

| 모델 | 훈련셋 정확도 | 테스트셋 정확도 | 테스트셋 F1 | Recall | Precision |
| --- | --- | --- | --- | --- | --- |
| 랜덤포레스트 | 0.955976 | 0.93644 | 0.5696 | 0.44935 | 0.77772 |
| XGB | 0.932168 | 0.931418 | 0.5466 | 0.4254 | 0.7644 |
| LGBM | 0.9046975 | 0.90421322 | 0.4339 | 0.3189 | 0.6789 |
| CatBoost | 0.95117 | 0.950626 | 0.6435 | 0.5279 | 0.8239 |

- 

| 모델 | 훈련셋 정확도 | 테스트셋 정확도 | 테스트셋 F1 | Recall | Precision |
| --- | --- | --- | --- | --- | --- |
| 랜덤포레스트 |  |  |  |  |  |
| XGB |  |  |  |  |  |
| LGBM |  |  |  |  |  |
| CatBoost |  |  |  |  |  |

```python
# 커널 PCA
from sklearn.decomposition import KernelPCA
rbf_pca = KernelPCA(n_components=2,kernel="rbf",gamma=0.04)
X_reduced = rbf_pca.fit_transform(X)

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

clf = Pipeline([
        ("kpca", KernelPCA(n_components=2)),
        ("log_reg", LogisticRegression(solver="lbfgs"))
    ])

param_grid = [{
        "kpca__gamma": np.linspace(0.03, 0.05, 10),
        "kpca__kernel": ["rbf", "sigmoid"]
    }]
# 커널 선택과 하이퍼파라미터 튜닝
grid_search = GridSearchCV(clf, param_grid, cv=3)
grid_search.fit(X, y)

```

랜덤포레스트

min_samples_split : 노드를 분할하기 위한 최소한의 샘플데이터 수. 작게 설정할수록 분할되는 노드가 많아지므로 과적합 가능성 증가

min_samples_leaf : 말단 노드가 되기 위한 최소한의 샘플 데이터 수. 과적합 제어용도로 활용하지만, 비대칭적 데이터의 경우 특정 작게 설정 필요

max_features : 최적의 분할을 위해 고려할 최대 Feature의 개수. 디폴트값은 None으로 모든 Feature 사용

- 'sqrt' : sqrt(전체 Feature 개수)
- 'auto' : sqrt와 동일
- 'log' : log2(전체 Feature 개수)
- 'None' : 전체 Feature 선정

max_depth : 트리의 최대 깊이. 디폴트는 None이며 노드가 가지는 데이터 수가 min_samples_split 보다 작아질 때까지 계속 증가

max_leaf_nodes : 말단 노드의 최대 개수

```jsx
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score
import pandas as pd

model = CatBoostClassifier(random_seed=42)
# parameter 넣어줄 값들 dict 형태로 정의해주기
h_para = {'n_estimators' : [1000,1500,2000], 'learning_rate':[0.1, 0.3, 0.5], 'max_depth':[3,4,5]}

grid_cat1 = GridSearchCV(model, param_grid=h_para,
                         cv=5, refit=True, return_train_score=True, scoring='f1')
grid_cat1.fit(X_under, y_under)

# 각 파라미터값들에 대한 모델 결과값들이 cv_results_ 객체에 할당됨
scores_df = pd.DataFrame(grid_cat1.cv_results_)
```

kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=200, random_state=0)

dbscan = DBSCAN(eps=0.6, min_samples=8, metric='euclidean')

```python
def elbow(X):
	sse = []
  for i in range(1, 11):
	    km = KMEANS
		km.fit
		sse.append(km.inertia

	plt.plot(range(1, 11), sse, marker='o')

```

```python
시간대별로 대출한도 평균 다르다는 것 검정

result_insert_time  = result.set_index('loanapply_insert_time')

result_insert_time_range_0to6 = result_insert_time[(pd.DatetimeIndex(result_insert_time.index).hour >=0) & (pd.DatetimeIndex(result_insert_time.index).hour <6)]
print(len(result_insert_time_range_0to6))
result_insert_time_range_6to12 = result_insert_time[(pd.DatetimeIndex(result_insert_time.index).hour >=6) & (pd.DatetimeIndex(result_insert_time.index).hour <12)]
print(len(result_insert_time_range_6to12))
result_insert_time_range_12to18 = result_insert_time[(pd.DatetimeIndex(result_insert_time.index).hour >=12) & (pd.DatetimeIndex(result_insert_time.index).hour <18)]
print(len(result_insert_time_range_12to18))
result_insert_time_range_18to24 = result_insert_time[(pd.DatetimeIndex(result_insert_time.index).hour >=18) & (pd.DatetimeIndex(result_insert_time.index).hour <24)]
print(len(result_insert_time_range_18to24))

data1=result_insert_time_range_0to6.iloc[:,[0,1,2,3,4]]
data1=data1.dropna(axis=0)

data2=result_insert_time_range_6to12.iloc[:,[0,1,2,3,4]]
data2=data2.dropna(axis=0)
data2.isna().sum()

data3=result_insert_time_range_12to18.iloc[:,[0,1,2,3,4]]
data3=data3.dropna(axis=0)
data3.isna().sum()

data4=result_insert_time_range_18to24.iloc[:,[0,1,2,3,4]]
data4=data4.dropna(axis=0)
data4.isna().sum()

import scipy.stats as stats
import numpy as np
F_statistic, pVal = stats.f_oneway(data1['loan_limit'],data2['loan_limit'],data3['loan_limit'],data4['loan_limit'])
print('F={0:.1f}, p={1:.5f}'.format(F_statistic,pVal))

df_new = pd.concat([data1,data2,data3,data4])
df_new.head(10)

from statsmodels.stats.multicomp import pairwise_tukeyhsd

posthoc = pairwise_tukeyhsd(df_new['loan_limit'], df_new['var'], alpha=0.05)
print(posthoc)
```

```python
train = train_set.copy()
train_noage = train_set_noage.copy()
test = test_set.copy()
test_noage = test_set_noage.copy()

impu = IterativeImputer(random_state = 77)
train = impu.fit_transform(train)
train = pd.DataFrame(train)
train.columns = train_set.columns
train_set = train
test = impu.transform(test)
test = pd.DataFrame(test)
test.columns = test_set.columns
test_set = test

impu_noage = IterativeImputer(random_state = 77)
train_noage = impu_noage.fit_transform(train_noage)
train_noage = pd.DataFrame(train_noage)
train_noage.columns = train_set_noage.columns
train_set_noage = train_noage

test_noage = impu.transform(test_noage)
test_noage = pd.DataFrame(test_noage)
test_noage.columns = test_set_noage.columns
test_set_noage = test_noage

del train, test, train_noage, test_noage
```

```python
train1 = train_set.drop(['yearly_income_stand', 'limit_desired_stand', 'existing_loan_amt_stand','is_applied'], axis=1)
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
train = train1.copy()
train = IterativeImputer(random_state = 77).fit_transform(train)
train = pd.DataFrame(train)
train.columns = train1.columns


y_pred_test = clf_cat.predict(test_set.drop(['application_id'], axis=1))

y_pred_test_noage = clf_cat_noage.predict(test_set_noage.drop(['application_id'], axis=1))

test_set = pd.concat([test_set['product_id', 'application_id'], y_pred_test])
test_set_noage = pd.concat([test_set_noage['product_id', 'application_id'], y_pred_test_noage])
test_set.columns = ['product_id', 'application_id', 'is_applied']
test_set_noage.columns = ['product_id', 'application_id', 'is_applied']

test_set = pd.concat([test_set, test_set_noage], axis=0)

test = pd.read_csv('~~~~~~~~~~~~~')
test.drop(['is_applied'], axis=1, inplace=True)

test = pd.merge(left = test , right = test_set, how = "left", on = ['product_id', 'application_id'])
test.to_csv('~~~~~')

```
